{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "XP_train=[]\n",
    "file=open(\"./ocr/train-data.csv\", 'r')\n",
    "for l in file:\n",
    "    app=[]\n",
    "    for d in l.split(','):\n",
    "        app.append(int(d))\n",
    "    XP_train.append(app)\n",
    "X_train=np.array(XP_train)\n",
    "\n",
    "XP_test=[]\n",
    "file=open(\"./ocr/test-data.csv\", 'r')\n",
    "for l in file:\n",
    "    app=[]\n",
    "    for d in l.split(','):\n",
    "        app.append(int(d))\n",
    "    XP_test.append(app)\n",
    "X_test=np.array(XP_test)\n",
    "\n",
    "YP_train=[]\n",
    "file=open(\"./ocr/train-targets.csv\", 'r')\n",
    "for l in file:\n",
    "    YP_train.append(l)\n",
    "Y_train=np.array(YP_train)\n",
    "\n",
    "YP_test=[]\n",
    "file=open(\"./ocr/test-targets.csv\", 'r')\n",
    "for l in file:\n",
    "    YP_test.append(l)\n",
    "Y_test=np.array(YP_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = X_test[2].reshape((16, 8))\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g\\n', 'a\\n', 'r\\n', ..., 'p\\n', 'm\\n', 'c\\n'], dtype='<U2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf =SVC(C=10, kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Training\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Prediction\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "Y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "report = metrics.classification_report(Y_test, Y_pred)\n",
    "\n",
    "# the support is the number of instances having the given label in y_test\n",
    "print(report)\n",
    "print(metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "    \n",
    "# 3-fold cross-validation\n",
    "# random_state ensures same split for each value of gamma\n",
    "# KFold has a different syntax for legacy versions of scikit-learn\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "gamma_values = [0.1, 0.05, 0.02, 0.01]\n",
    "accuracy_scores = []\n",
    "\n",
    "# Do model selection over all the possible values of gamma \n",
    "for gamma in gamma_values:\n",
    "    \n",
    "    # Train a classifier with current gamma\n",
    "    clf = SVC(C=10, kernel='rbf', gamma=gamma)\n",
    "\n",
    "    # Compute cross-validated accuracy scores\n",
    "    # So legacy....\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv=kf.split(X_train), scoring='accuracy')\n",
    "    \n",
    "    # Compute the mean accuracy and keep track of it\n",
    "    accuracy_score = scores.mean()\n",
    "    accuracy_scores.append(accuracy_score)\n",
    "\n",
    "# Get the gamma with highest mean accuracy\n",
    "best_index = np.array(accuracy_scores).argmax()\n",
    "best_gamma = gamma_values[best_index]\n",
    "\n",
    "# Train over the full training set with the best gamma\n",
    "clf = SVC(C=10, kernel='rbf', gamma=best_gamma)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "Y_pred = clf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import learning_curve\n",
    "except ImportError:\n",
    "    from sklearn.learning_curve import learning_curve\n",
    "    \n",
    "    \n",
    "plt.figure()\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "clf = SVC(C=10, kernel='rbf', gamma=best_gamma)\n",
    "\n",
    "# Compute the scores of the learning curve\n",
    "# by default the (relative) dataset sizes are: 10%, 32.5%, 55%, 77.5%, 100%\n",
    "# The function automatuically executes a Kfold cross validation for each dataset size\n",
    "train_sizes, train_scores, val_scores = learning_curve(clf, X_train, Y_train, scoring='accuracy', cv=3)\n",
    "\n",
    "# Get the mean and std of train and validation scores over the cv folds along the varying dataset sizes\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "val_scores_mean = np.mean(val_scores, axis=1)\n",
    "val_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot the mean  for the training scores\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "\n",
    "# Plot the  std for the training scores\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "\n",
    "# Plot the mean  for the validation scores\n",
    "plt.plot(train_sizes, val_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "# Plot the std for the validation scores\n",
    "plt.fill_between(train_sizes, val_scores_mean - val_scores_std,\n",
    "                 val_scores_mean + val_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.ylim(0.05,1.3)             # set bottom and top limits for y axis\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
